{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPsb_X6vqeRK"
   },
   "source": [
    "# 2024-1 DSL 정규세션 과제\n",
    "\n",
    "## SVM\n",
    "\n",
    "- 작성자 : 윤형진\n",
    "- 참고자료 : sklearn document\n",
    "- 과제 제출 기한 : 02.03\n",
    "\n",
    "---\n",
    "- 이름 : 한은결 \n",
    "- 기수 : 11기    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23901,
     "status": "ok",
     "timestamp": 1706254087254,
     "user": {
      "displayName": "HYUNGJIN YOON",
      "userId": "17119910277856849366"
     },
     "user_tz": -540
    },
    "id": "-ucNXmPIlxEU",
    "outputId": "a4d1f902-e489-409f-86dc-02f8b222f6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.5-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from umap-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from umap-learn) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from umap-learn) (1.3.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from umap-learn) (0.57.1)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Obtaining dependency information for pynndescent>=0.5 from https://files.pythonhosted.org/packages/4e/82/0b9851a2fd4da9b57d7931446f5ebab92a98f1f35d3dc0dae5f9ed50a462/pynndescent-0.5.11-py3-none-any.whl.metadata\n",
      "  Using cached pynndescent-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.40.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ekhan\\anaconda3\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n",
      "Using cached pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: pynndescent, umap-learn\n",
      "Successfully installed pynndescent-0.5.11 umap-learn-0.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3O0DH8jsRBL"
   },
   "source": [
    "# 1. SVM을 이용한 심장병 예측 모델\n",
    "\n",
    "해당 섹션에서는 범주형 데이터 더미 변수화, 전처리, train_test_split, confusion matrix까지 그려보는 전체적인 머신러닝 프로젝트 과정을 실습해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ztIrWd5FkKFv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.svm import SVC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yVh6Kd1OlbUi"
   },
   "outputs": [],
   "source": [
    "# heart.csv 데이터셋을 로드해주세요\n",
    "df = pd.read_csv(\"C:/Users/ekhan/OneDrive/바탕 화면/DSL/회귀_SVM_비지도 통합과제/SVM/heart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5tEh7uEs0BG"
   },
   "source": [
    "## 데이터 전처리\n",
    "- 범주형 데이터 : pd.get_dummies(데이터 프레임, columns = 범주형 데이터를 담은 칼럼들의 리스트, drop_first = True)\n",
    "- 데이터 스케일링 : 연속형 데이터에 대해서 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "92ucnlRul6B6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                918 non-null    float64\n",
      " 1   RestingBP          918 non-null    float64\n",
      " 2   Cholesterol        918 non-null    float64\n",
      " 3   FastingBS          918 non-null    float64\n",
      " 4   MaxHR              918 non-null    float64\n",
      " 5   Oldpeak            918 non-null    float64\n",
      " 6   Sex_M              918 non-null    bool   \n",
      " 7   ChestPainType_ATA  918 non-null    bool   \n",
      " 8   ChestPainType_NAP  918 non-null    bool   \n",
      " 9   ChestPainType_TA   918 non-null    bool   \n",
      " 10  RestingECG_Normal  918 non-null    bool   \n",
      " 11  RestingECG_ST      918 non-null    bool   \n",
      " 12  ExerciseAngina_Y   918 non-null    bool   \n",
      " 13  ST_Slope_Flat      918 non-null    bool   \n",
      " 14  ST_Slope_Up        918 non-null    bool   \n",
      " 15  HeartDisease       918 non-null    int64  \n",
      "dtypes: bool(9), float64(6), int64(1)\n",
      "memory usage: 58.4 KB\n"
     ]
    }
   ],
   "source": [
    "label = df[\"HeartDisease\"]\n",
    "\n",
    "df_processed = df.drop(columns=[\"HeartDisease\"])\n",
    "\n",
    "# 범주형 데이터를 전처리해줍니다\n",
    "categorical_col =  [\"Sex\", \"ChestPainType\", \"RestingECG\" , \"ExerciseAngina\" , \"ST_Slope\" ]\n",
    "\n",
    "df_processed=pd.get_dummies(df_processed,columns=categorical_col,drop_first=True)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for feature in [\"Age\", \"RestingBP\", \"Cholesterol\", \"FastingBS\", \"MaxHR\", \"Oldpeak\"]:\n",
    "    df_processed[feature] = scaler.fit_transform(pd.DataFrame(df_processed[feature]))\n",
    "\n",
    "df_processed[\"HeartDisease\"] = label\n",
    "\n",
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FVS9rpTtPgw"
   },
   "source": [
    "## Train dataset, Test Dataset 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IF7sF0tHtPIM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size : (734, 16) Test Dataset Size : (184, 16)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df_processed, test_size=0.2, random_state=777)\n",
    "\n",
    "print(f\"Train Dataset Size : {train.shape}\", f\"Test Dataset Size : {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Up3U2eHCvCuE"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = train.iloc[:, :-1], train.iloc[:,-1]\n",
    "x_test, y_test = test.iloc[:, :-1], test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYUtE3IOti18"
   },
   "source": [
    "## 다양한 조건으로 실험 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bEFCD4qJtsA5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cReiqGpZtWN7"
   },
   "outputs": [],
   "source": [
    "def Run_Classification(name : str, model : object, x_train : object, y_train : object, x_test:object, y_test:object):\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    cf_matrix = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='crest', linewidth=.5)\n",
    "    cf_matrix = cf_matrix.get_figure()\n",
    "\n",
    "    print(f\"Classification Result of {name}\", \"\\n\")\n",
    "    print(f\"accuracy : {acc}\", \"\\n\")\n",
    "    print(f\"report : {report}\", \"\\n\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ase8I3Apt5jz"
   },
   "source": [
    "# 커널의 종류에 따른 모델 퍼포먼스 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0IO5Agjtrki"
   },
   "outputs": [],
   "source": [
    "kernel_models = {\"linear\" : SVC(kernel=\"linear\"),\n",
    "                 \"rbf_kernel\" : SVC(kernel=\"rbf\"),\n",
    "                 \"poly_kernel\" : SVC(kernel=\"poly\")}\n",
    "\n",
    "for kernel_type, model in kernel_models.items():\n",
    "  Run_Classification(kernel_type, model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfgTXXxavhPr"
   },
   "source": [
    "## C Parameter와 Soft/Hard Margin SVM\n",
    "- C parameter는 SVM의 Regularization 파라미터로서, 클수록 Hard Margin SVM의 방향으로 학습됩니다.\n",
    "<br>\n",
    "(즉, 테스트 데이터셋에서 한 개의 miss-classification도 허용하지 않는 방향으로)\n",
    "<br>\n",
    "    - 이상치가 적은 경우 : 큰 C\n",
    "    <br>\n",
    "    - 이상치가 많은 경우 : 작은 C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_rz4XqwxtFl"
   },
   "outputs": [],
   "source": [
    "c_models = {'rbf_SVC_C=0.5': SVC(C=0.5),\n",
    "            'rbf_SVC_C=1': SVC(C=1),\n",
    "            'rbf_SVC_C=3': SVC(C=3),\n",
    "            'rbf_SVC_C=4': SVC(C=4),\n",
    "            'rbf_SVC_C=5': SVC(C=5),\n",
    "            'rbf_SVC_C=10': SVC(C=10)}\n",
    "\n",
    "for name, model in c_models.items():\n",
    "  Run_Classification(name, model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ-qVZx4zV9x"
   },
   "source": [
    "# gamma 파라미터와 RBF Kernel\n",
    "\n",
    "RBF 함수가 각 데이터 포인트와 이웃 데이터 포인트의 유사도를 계산하는 함수의 일종이었다는 걸 기억하시나요?\n",
    "gamma 파라미터는 그중에서도 한 데이터 포인트로부터 유사하다고 판단되는 거리를 조절하는 파람미터로, gamma가 커질수록 더 좁은 반경의 데이터 포인트만을 유사하다고 판단하게 됩니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "즉, gamma가 클수록, 경계곡면 (decision boundary)는 데이터의 분포에 더 예민하게 반응하여, 더 굴곡지게 됩니다. 따라서 적절한 크기의 gamma는 더 정확한 경계곡면이 학습되도록 도와줄 수도 있지만, 과도한 경우 overfitting을 야기시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFr1VmMy0qGw"
   },
   "outputs": [],
   "source": [
    "gamma_models = {'rbf_SVC_gamma=0.2': SVC(C=0.2),\n",
    "                'rbf_SVC_gamma=0.5': SVC(C=0.5),\n",
    "                'rbf_SVC_gamma=1': SVC(C=1),\n",
    "                'rbf_SVC_gamma=4': SVC(C=4),\n",
    "                'rbf_SVC_gamma=8': SVC(C=8),\n",
    "                'rbf_SVC_gamma=16': SVC(C=16)}\n",
    "\n",
    "for name, model in gamma_models.items():\n",
    "  Run_Classification(name, model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRbFXTwy1RgT"
   },
   "source": [
    "# 2. 여러 파라미터에 의한 결정 경계 변화 시각화\n",
    "\n",
    "일전에 C 파라미터를 통한 Soft/Harm Margin SVM 조절을, gamma 파라미터를 통해 경계곡면의 굴곡도를 조정하는 것이 Model Metric에 어떤 영향을 주는 지 관찰했습니다. 이 변화를 시각화하기 위해서는 15 차원인 데이터를 2차원으로 축소할 필요가 있습니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "해당 섹션에서는 UMAP의 힘을 빌려 파라미터 변화에 따른 경계곡면의 변화 양상을 시각화하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trZOeScF9nE7"
   },
   "outputs": [],
   "source": [
    "umap_instance = umap.UMAP(metric=\"cosine\")\n",
    "embedding = umap_instance.fit_transform(df_processed.iloc[:, :-1])\n",
    "embedding_df = pd.DataFrame(embedding)\n",
    "embedding_df[\"HeartDisease\"] = df_processed[\"HeartDisease\"]\n",
    "\n",
    "# Get unique classes\n",
    "classes = embedding_df[\"HeartDisease\"].unique()\n",
    "\n",
    "# Create a scatter plot for each class\n",
    "for i, class_ in enumerate(classes):\n",
    "    plt.scatter(embedding_df[embedding_df[\"HeartDisease\"]==class_].iloc[:,0],\n",
    "                embedding_df[embedding_df[\"HeartDisease\"]==class_].iloc[:,1],\n",
    "                label=f'Class {class_}')\n",
    "\n",
    "plt.title('UMAP projection of datapoints')\n",
    "plt.xlabel(\"UMAP1\")\n",
    "plt.ylabel(\"UMAP2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWRLBoJcqFqY"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(embedding_df, test_size = 0.3, random_state=777)\n",
    "\n",
    "x_train, y_train = train.iloc[:, :-1], train.iloc[:,-1]\n",
    "x_test,  y_test  = test.iloc[:, :-1],  test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NFuQiEw4CCU"
   },
   "source": [
    "## 2-1. Kernel 종류에 따른 경계 곡면 변화 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Lqd6ltnstst"
   },
   "outputs": [],
   "source": [
    "models = dict()\n",
    "\n",
    "models[\"rbf\"] = SVC(C = 4,  kernel=\"rbf\")\n",
    "models[\"poly\"] = SVC(C = 4, kernel=\"poly\")\n",
    "models[\"linear\"] = SVC(C=4, kernel=\"linear\")\n",
    "\n",
    "poly_svc = models[\"poly\"].fit(x_train, y_train)\n",
    "rbf_svc = models[\"rbf\"].fit(x_train, y_train)\n",
    "linear_svc = models[\"linear\"].fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmOSZREHtRmP"
   },
   "outputs": [],
   "source": [
    "h = .02\n",
    "x_min, x_max = x_train.iloc[:, 0].min() - 1, x_train.iloc[:, 0].max() + 1\n",
    "y_min, y_max = x_train.iloc[:, 1].min() - 1, x_train.iloc[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Plot the decision boundary for polynomial kernel\n",
    "Z = poly_svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "plt.scatter(x_train.iloc[:, 0], x_train.iloc[:, 1], c=y_train, cmap=plt.cm.coolwarm)\n",
    "plt.title('Polynomial Kernel')\n",
    "plt.show()\n",
    "\n",
    "# Plot the decision boundary for RBF kernel\n",
    "Z = rbf_svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "plt.scatter(x_train.iloc[:, 0], x_train.iloc[:, 1], c=y_train, cmap=plt.cm.coolwarm)\n",
    "plt.title('RBF Kernel')\n",
    "plt.show()\n",
    "\n",
    "# Plot the decision boundary for linear kernel\n",
    "Z = linear_svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "plt.scatter(x_train.iloc[:, 0], x_train.iloc[:, 1], c=y_train, cmap=plt.cm.coolwarm)\n",
    "plt.title('Linear SVC Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hT4Tp5iC6NWs"
   },
   "outputs": [],
   "source": [
    "rbf_models = {\"C=0.5, gamma=0.5\" : SVC(C=0.5, gamma = 0.5, kernel=\"rbf\"), \"C=0.5, gamma=2\"  : SVC(C=0.5, gamma = 2, kernel=\"rbf\"), \"C=0.5, gamma=5\" : SVC(C=0.5, gamma = 5, kernel=\"rbf\"),\n",
    "              \"C=2, gamma=0.5\"   : SVC(C=2, gamma = 0.5, kernel=\"rbf\"),   \"C=2, gamma=2\"    : SVC(C=2, gamma = 2, kernel=\"rbf\"),   \"C=2, gamma=5\"   : SVC(C=2, gamma = 5, kernel=\"rbf\"),\n",
    "              \"C=5, gamma=0.5\"   : SVC(C=5, gamma = 0.5, kernel=\"rbf\"),   \"C=5, gamma=2\"   : SVC(C=5, gamma = 2, kernel=\"rbf\"),   \"C=5, gamma=5\"   : SVC(C=5, gamma = 5, kernel=\"rbf\")}\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, (name, model) in enumerate(rbf_models.items()):\n",
    "  rbf_svc = model.fit(x_train, y_train)\n",
    "\n",
    "  h = .02\n",
    "  x_min, x_max = x_train.iloc[:, 0].min() - 1, x_train.iloc[:, 0].max() + 1\n",
    "  y_min, y_max = x_train.iloc[:, 1].min() - 1, x_train.iloc[:, 1].max() + 1\n",
    "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "  Z = rbf_svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "  Z = Z.reshape(xx.shape)\n",
    "  axs[i].contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "  axs[i].scatter(x_train.iloc[:, 0], x_train.iloc[:, 1], c=y_train, cmap=plt.cm.coolwarm)\n",
    "  axs[i].set_title(f'{name} Decision Boundary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A63Ixv_Y-qMo"
   },
   "source": [
    "# 3. 문제\n",
    "위의 예시를 참고하여 적절한 파라미터를 가진 SVC를 이용해 87% 이상의 accuracy를 내도록 하십시오. accuracy, f1 score와 함께 confusion matrix도 함께 plot 해주세요.\n",
    "\n",
    "(Run_Classification() 함수를 사용해도 좋습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCkY_VlbBQsX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMl9HlhSuseWeQjldGXM4SJ",
   "mount_file_id": "1P_WXHCNw7jL191X-AxQjYdWLDV3HpUvh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
